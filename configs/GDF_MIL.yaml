General:
    MODEL_NAME: GDF_MIL
    seed: 2024
    num_classes: 2
    num_epochs: 5
    device: 1
    num_workers: 4
    best_model_metric: macro_auc  
    earlystop: 
        use: False
        patience: 5
        metric: macro_auc

Dataset:
    DATASET_NAME: your_dataset_name
    # to use train-val-test, open dataset_csv_dir
    # to use k-fold train-val/k-fold train-val then test, open dataset_root_dir
    
    dataset_csv_path: /path/to/your/dataset.csv
    # dataset_root_dir: /dir/to/your/dataset_dir/
    balanced_sampler:
        use: False
        replacement: True

Logs:
    log_root_dir: /path/to/your/log_dir/


Model:
    in_dim: 1024  # depend on the pt dimensions，such resnet50——>1024 vit_s——>384
    hid_dim: 256  # hidden dimension after encoder
    out_dim: 128  # output dimension for graph and attention features
    k_components: 10  # number of components for bag partition
    k_neighbors: 10  # number of neighbors for graph construction
    dropout: 0.1  # dropout rate
    act: leaky_relu  # activation function: relu, leaky_relu, gelu, tanh
    lambda_smooth: 0.0  # smoothness regularization weight
    lambda_nce: 0.0  # contrastive learning weight
    optimizer:
        which: adam    # adam or adamw
        adam_config:
            lr: 0.0002
            weight_decay: 0.00001
        adamw_config:
            lr: 0.0002
            weight_decay: 0.00001
    criterion: ce  
    scheduler:
        warmup: 2
        which: step  # [step, cosine,multi_step,exponential]
        step_config:
            step_size: 3 # absolute step size, should ensure that step_size > warmup
            gamma: 0.9
        multi_step_config:
            milestones: [20, 30, 40] # absolute milestones, should ensure that milestones > warmup
            gamma: 0.9
        exponential_config:
            gamma: 0.9 # begin after warmup
        cosine_config:
            T_max: 10 # interval of cosine annealing, begin after warmup
            eta_min: 0.0001
            


        

    
     

